# Causes of LLM Hallucination

* No intrinsic capacity to evaluate correctness
* Most likely answer doesn't mean correct
* Training data may lack sufficiant material
* Training data includes fictional accounts and opinion pieces
* Stochastic variance to encourage novelty

* https://moebio.com/mind/

# Limitation s for Naive RAG models

* Issues with precision & Recall
* LLM may halluocinate

Naive RAG, Advanced RAG, Modular RAG
